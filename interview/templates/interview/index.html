<!DOCTYPE html>
<html>
<head>
    <title>AI Interviewer</title>
    <style>
        body { font-family: Arial; background: lavender; display: flex; justify-content: center; align-items: center; height: 100vh; }
        .container { background: white; width: 550px; padding: 30px; border-radius: 12px; box-shadow: 0 10px 25px rgba(0,0,0,0.1); }
        h2 { text-align: center; }
        .section { margin-top: 20px; }
        .box { background: #f9fafb; padding: 12px; border-radius: 8px; min-height: 60px; }
        button { padding: 8px 14px; border: none; border-radius: 6px; cursor: pointer; margin-right: 8px; }
        .primary { background: #2563eb; color: white; }
        .success { background: #16a34a; color: white; }
        .danger { background: #dc2626; color: white; }
        button:disabled { opacity: 0.5; cursor: not-allowed; }
    </style>
</head>
<body>
<div class="container">
    <h2>ðŸŽ¤ AI Interviewer</h2>

    <div class="section">
        <strong>INTERVIEWER:</strong>
        <div class="box" id="aiText"></div>
    </div>

    <div class="section">
        <strong>CANDIDATE:</strong>
        <div class="box" id="userText"></div>
    </div>

    <div class="section">
        <button id="startBtn" class="primary">Start Interview</button>
        <button id="recordBtn" class="success" disabled>Start Answer</button>
        <button id="doneBtn" class="danger" disabled>Done</button>
    </div>

    <audio id="audioPlayer" controls></audio>
</div>

<script>
let mediaRecorder, audioChunks = [], streamRef, timeout;
const aiTextEl = document.getElementById("aiText");
const userTextEl = document.getElementById("userText");
const audioPlayer = document.getElementById("audioPlayer");
const startBtn = document.getElementById("startBtn");
const recordBtn = document.getElementById("recordBtn");
const doneBtn = document.getElementById("doneBtn");

// ---------------- TIMER ----------------
function startTimer() {
    clearTimeout(timeout);
    timeout = setTimeout(() => {
        aiTextEl.innerText = "Thank you for your interview.";
        recordBtn.disabled = true;
        doneBtn.disabled = true;
    }, 5000);
}
function clearTimer() { clearTimeout(timeout); }

// ---------------- PLAY AUDIO ----------------
async function playAIAudio(url) {
    return new Promise(resolve => {
        audioPlayer.src = url;
        audioPlayer.play().catch(err => console.warn("Audio autoplay blocked:", err));
        audioPlayer.onended = () => {
            startTimer();
            resolve();
        };
    });
}

// ---------------- START INTERVIEW ----------------
startBtn.addEventListener("click", async () => {
    aiTextEl.innerText = "AI is starting...";
    userTextEl.innerText = "";
    recordBtn.disabled = true;
    doneBtn.disabled = true;

    try {
        const res = await fetch("/start/", { method: "POST" });
        const data = await res.json();

        aiTextEl.innerText = data.ai_text || "[No response]";
        localStorage.setItem("session_key", data.session_key);

        if (data.audio_url) await playAIAudio(data.audio_url);

        recordBtn.disabled = false;
        doneBtn.disabled = false;
    } catch (err) {
        console.error(err);
        aiTextEl.innerText = "Error starting interview.";
    }
});

// ---------------- RECORD ----------------
recordBtn.addEventListener("click", async () => {
    clearTimer();
    userTextEl.innerText = "Recording...";
    recordBtn.disabled = true;
    doneBtn.disabled = false;

    try {
        streamRef = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(streamRef);
        audioChunks = [];
        mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
        mediaRecorder.start();
    } catch (err) {
        console.error("Microphone access denied:", err);
        userTextEl.innerText = "Cannot access microphone.";
        recordBtn.disabled = false;
    }
});

// ---------------- STOP RECORDING ----------------
doneBtn.addEventListener("click", async () => {
    doneBtn.disabled = true;
    if (!mediaRecorder) return;

    mediaRecorder.stop();
    mediaRecorder.onstop = async () => {
        // Stop mic
        streamRef.getTracks().forEach(track => track.stop());
        const blob = new Blob(audioChunks, { type: "audio/webm" });

        // ---------------- SILENCE DETECTION ----------------
        if (blob.size < 1000) { // very small blob => likely silence
            userTextEl.innerText = "[No speech detected]";
            recordBtn.disabled = false;
            doneBtn.disabled = false;
            return; // skip transcription and AI call
        }

        // ---------------- TRANSCRIBE ----------------
        let candidateAnswer = "[Transcription failed]";
        try {
            const form = new FormData();
            form.append("audio_file", blob);
            const res = await fetch("/transcribe/", { method: "POST", body: form });
            const data = await res.json();

            candidateAnswer = data.text || "[No transcription]";
            userTextEl.innerText = candidateAnswer; // show candidate text immediately

        } catch (err) {
            console.error("Transcription error:", err);
            userTextEl.innerText = "[Transcription failed]";
        }

        // ---------------- SEND TO AI ----------------
        try {
            const res2 = await fetch("/interview/", {
                method: "POST",
                headers: { "Content-Type": "application/x-www-form-urlencoded" },
                body: `audio_text=${encodeURIComponent(candidateAnswer)}`
            });
            const aiData = await res2.json();

            aiTextEl.innerText = aiData.ai_text || "[No response]";
            if (aiData.audio_url) await playAIAudio(aiData.audio_url);

        } catch (err) {
            console.error("AI response error:", err);
        }

        recordBtn.disabled = false;
        doneBtn.disabled = false;
        startTimer();
    };
});

</script>
</body>
</html>
